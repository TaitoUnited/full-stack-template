global:
  domain: ${taito_domain}
  url: https://${taito_domain}
  logFormat: stackdriver
  logLevel: info    # trace, debug, info, warn, error, fatal
  registry: ${taito_image_registry}
  imagePullPolicy: ''

server-template:
  ingress:
    class: nginx
    tls: true
    maxBodySize: 1m
    basicAuth:
      enabled: true
      htpasswdSecret: ${taito_project}-${taito_env}-basic-auth
    domains:
      - name: ${taito_domain}

  serviceDefaults:
    # Basics
    image: # For 3rd party container image
    command:
    path:
    port: 8080
    tier:
    livenessPath: /healthz
    # Security
    runAsUser:
    fsGroup:
    # Resources
    cpuRequest: 2m
    cpuLimit: 100m
    memoryRequest: 50Mi
    memoryLimit: 256Mi
    # Scaling
    replicas: ${kubectl_replicas}
    autoscale: false
    minReplicas: 2
    maxReplicas: 5
    # TODO metrics:
    # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/
    # TODO vertical autoscaling:
    # https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling
    # Env
    env:
      # Environment variables
      COMMON_ENV: ${taito_env}
    secrets:
      # Secrets

  services:

    admin:
      path: /admin
      tier: frontend
      memoryRequest: 2Mi

    client:
      path: /
      tier: frontend
      memoryRequest: 2Mi

    cache:
      image: redis:alpine
      port: 6397
      tier: backend
      livenessDisabled: true # TODO remove
      memoryRequest: 5Mi
      runAsUser: 2
      fsGroup: 2

    graphql:
      path: /graphql
      tier: backend
      memoryRequest: 50Mi
      env:
        DEBUG: false
        GRAPHQL_PORT: '8080'
        GRAPHQL_BINDADDR: '0.0.0.0'
        API_HOST: ${taito_project}-${taito_env}-server
        API_PORT: '8080'

    server:
      path: /api
      tier: backend
      memoryRequest: 50Mi
      db:
        instance: ${taito_zone}:${taito_provider_region}:${db_database_instance}
        port: 5432
        proxySecret: cloudsql-gserviceaccount.key
      serviceAccount:
        secret: ${taito_project}-${taito_env}-gserviceaccount.key
      secrets:
        S3_KEY_SECRET: ${taito_project}-${taito_env}-storage-gateway.secret
        DATABASE_PASSWORD: ${taito_project}-${taito_env}-db-app.password
      env:
        DEBUG: false
        SENTRY_DSN: #sentryDSN
        API_PORT: '8080'
        API_BINDADDR: '0.0.0.0'
        DATABASE_HOST: '127.0.0.1'
        DATABASE_PORT: '5432'
        DATABASE_NAME: ${db_database_name}
        DATABASE_USER: ${db_database_name}_app
        DATABASE_POOL_MIN: '5'
        DATABASE_POOL_MAX: '10'
        S3_URL: http://${taito_project}-${taito_env}-storage:9000/
        S3_REGION: ${taito_provider_region}
        S3_BUCKET: ${taito_project}-${taito_env}
        S3_KEY_ID: 070UEOQR6LX4YPZLFU0V
      # cron jobs that re-use the same Docker image and settings as server
      # cronJobs:
      #   - name: examplejob1
      #     schedule: "30 2 * * *"
      #     args:
      #       - /bin/sh
      #       - -c
      #       - date; echo Hello from server

    storage:
      image: minio/minio
      port: 9000
      tier: backend
      livenessPath: /minio/health/ready
      memoryRequest: 20Mi
      runAsUser: 2
      fsGroup: 2
      command:
        - minio
        - gateway
        - gcs
        - ${taito_resource_namespace}
      serviceAccount:
        secret: ${taito_project}-${taito_env}-gserviceaccount.key
      secrets:
        MINIO_SECRET_KEY: ${taito_project}-${taito_env}-storage-gateway.secret
      env:
        MINIO_ACCESS_KEY: 070UEOQR6LX4YPZLFU0V

    worker:
      enabled: false
      memoryRequest: 50Mi

    www:
      path: /docs
      tier: frontend
      memoryRequest: 2Mi
      sidecar:
        enabled: false
        name: webhook
        path: /webhook
        port: 9000
        sharedVolume:
          mountPath: /service
          sidecarMountPath: /build
        livenessDisabled: true
        secrets:
          WEBHOOK_URL_PREFIX: ${taito_project}-${taito_env}-webhook.urlprefix
          WEBHOOK_GIT_TOKEN: ${taito_project}-${taito_env}-webhook.gittoken
        env:
          GIT_REPOSITORY_URL: ${taito_vc_repository_url}.git

    scheduler:
      enabled: false
      type: job
      image: buildpack-deps:curl
      memoryRequest: 1Mi
      runAsUser: 2
      fsGroup: 2
      secrets:
        SCHEDULER_SECRET: ${taito_project}-${taito_env}-scheduler.secret
      cronJobs:
        - name: examplejob2
          schedule: "0 2 * * *"
          args:
            - /bin/sh
            - -c
            - curl -sS -H "X-Secret: $SCHEDULER_SECRET" 'http://${taito_project}-${taito_env}-server:8080/posts?offset=0&limit=1'

    # TODO: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#ttl-mechanism-for-finished-jobs
