global:
  domain: ${taito_domain}
  url: https://${taito_domain}
  publicPort: 443
  logFormat: stackdriver
  logLevel: info    # trace, debug, info, warn, error, fatal
  registry: ${taito_container_registry}
  imagePullPolicy: ''
  debug: false

full-stack:
  persistence:
    enabled: false
    existingClaim:
    storageClass:
    # NOTE: Google does not support ReadWriteMany
    # --> all containers will be placed on the same Kubernetes node
    accessMode: ReadWriteOnce
    size: 8Gi

  ingress:
    class: nginx
    oldRewritePolicy: false
    tls: true
    domains:
      - name: ${taito_domain}

  serviceDefaults:
    # Basics
    image: # For 3rd party container image
    command:
    port: 8080
    tier:
    livenessPath: /healthz
    livenessInitialDelay: 3
    # Paths
    paths:
      # - path:
      #   basicAuthEnabled:
      #   basicAuthHtpasswdSecret:
      #   clientMaxBodySize:
      #   readTimeout:
      #   limitRate:
      #   limitRateAfter:
      #   rewriteTarget:
      #   rewriteTargetDisabled:
    # Path defaults
    basicAuthEnabled: ${taito_basic_auth_enabled}
    basicAuthHtpasswdSecret: ${taito_project}-${taito_env}-basic-auth
    clientMaxBodySize: 1m
    readTimeout: 60
    limitRate:
    limitRateAfter:
    rewriteTarget:
    rewriteTargetDisabled:
    # Security
    runAsUser:
    runAsGroup:
    # Resources
    cpuRequest: 2m
    cpuLimit: 100m
    memoryRequest: 50Mi
    memoryLimit: 256Mi
    # Scaling
    replicas: ${kubernetes_replicas}
    autoscale: false
    minReplicas: 2
    maxReplicas: 5
    # TODO metrics:
    # https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/
    # TODO vertical autoscaling:
    # https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling
    # Sidecar
    sidecar:
    # Mounts
    temporaryVolumeMounts:
      # - mountPath: /mnt/data
      #   volumePath: data
      #   readOnly: false
    persistentVolumeMounts:
      # - mountPath: /mnt/data
      #   volumePath: data
      #   readOnly: false
    # Env
    secrets:
      # Secrets as mounted files
    secretEnv:
      # Secrets as environment variables (not recommended)
    env:
      # Environment variables
      COMMON_ENV: ${taito_env}

  services:

    admin:
      paths:
        - path: /admin
      tier: frontend
      memoryRequest: 2Mi

    client:
      paths:
        - path:
      tier: frontend
      memoryRequest: 2Mi

    cache:
      image: redis:5.0-alpine
      replicas: 1
      port: 6397
      tier: backend
      livenessDisabled: true # TODO remove
      memoryRequest: 5Mi
      runAsUser: 2
      runAsGroup: 2

    graphql:
      paths:
        - path: /graphql
      tier: backend
      memoryRequest: 50Mi
      env:
        DEBUG: false
        GRAPHQL_PORT: '8080'
        GRAPHQL_BINDADDR: '0.0.0.0'
        API_HOST: ${taito_project}-${taito_env}-server
        API_PORT: '8080'

    # TODO: proper setup for Kafka
    kafka:
      enabled: false
      image: bitnami/kafka:latest
      replicas: 1
      port: 9092
      tier: backend
      livenessDisabled: true # TODO remove
      memoryRequest: 100Mi
      memoryLimit: 512Mi
      env:
        KAFKA_ZOOKEEPER_CONNECT: ${taito_project}-${taito_env}-zookeeper:2181
        ALLOW_PLAINTEXT_LISTENER: 'yes'

    # TODO: proper setup for Zookeeper
    zookeeper:
      enabled: false
      image: bitnami/zookeeper:latest
      replicas: 1
      port: 2181
      tier: backend
      livenessDisabled: true # TODO remove
      memoryRequest: 100Mi
      memoryLimit: 512Mi
      env:
        ALLOW_ANONYMOUS_LOGIN: 'yes'

    server:
      paths:
        - path: /api
      tier: backend
      memoryRequest: 50Mi
      livenessInitialDelay: 120
      db:
        instance: ${taito_zone}:${taito_provider_region}:${db_database_instance}
        port: 5432
        proxySecret: cloudsql-gserviceaccount.key
      serviceAccount:
        secret: ${taito_project}-${taito_env}-gserviceaccount.key
      secrets:
        DATABASE_PASSWORD: ${db_database_app_secret}
        S3_KEY_SECRET: ${taito_project}-${taito_env}-storage-gateway.secret
      env:
        DEBUG: false
        SENTRY_DSN: #sentryDSN
        API_PORT: '8080'
        API_BINDADDR: '0.0.0.0'
        KAFKA_HOST: ${taito_project}-${taito_env}-kafka
        KAFKA_PORT: 9092
        DATABASE_HOST: '${db_database_real_host}'
        DATABASE_PORT: '${db_database_real_port}'
        DATABASE_NAME: ${db_database_name}
        DATABASE_USER: ${db_database_name}_app
        DATABASE_POOL_MIN: '5'
        DATABASE_POOL_MAX: '10'
        S3_URL: http://${taito_project}-${taito_env}-storage:9000/
        S3_REGION: ${taito_provider_region}
        S3_BUCKET: ${taito_random_name}-${taito_env}
        S3_KEY_ID: 070UEOQR6LX4YPZLFU0V
      # cron jobs that re-use the same Docker image and settings as server
      # cronJobs:
      #   - name: examplejob1
      #     schedule: "30 2 * * *"
      #     args:
      #       - /bin/sh
      #       - -c
      #       - date; echo Hello from server

    storage:
      image: minio/minio:RELEASE.2019-03-27T22-35-21Z
      port: 9000
      tier: backend
      livenessPath: /minio/health/ready
      memoryRequest: 20Mi
      runAsUser: 2
      runAsGroup: 2
      command:
        - minio
        - gateway
        - gcs
        - ${taito_resource_namespace}
      serviceAccount:
        secret: ${taito_project}-${taito_env}-gserviceaccount.key
      secretEnv:
        # Minio requires secret as environment variable in gateway mode
        MINIO_SECRET_KEY: ${taito_project}-${taito_env}-storage-gateway.secret
      env:
        MINIO_ACCESS_KEY: 070UEOQR6LX4YPZLFU0V
        MINIO_CONFIG_DIR: /tmp

    worker:
      enabled: false
      memoryRequest: 50Mi

    www:
      paths:
        - path: /docs
      tier: frontend
      memoryRequest: 2Mi
      sidecar:
        enabled: false
        name: webhook
        paths:
          - path: /webhook
        port: 9000
        sharedVolume:
          mountPath: /service
          sidecarMountPath: /build
        livenessDisabled: true
        secrets:
          WEBHOOK_URL_PREFIX: ${taito_project}-${taito_env}-webhook.urlprefix
          WEBHOOK_VC_TOKEN: ${taito_project}-${taito_env}-webhook.gittoken
        env:
          VC_REPOSITORY_URL: ${taito_vc_repository_url}

    scheduler:
      enabled: false
      type: job
      image: buildpack-deps:curl
      memoryRequest: 1Mi
      runAsUser: 2
      runAsGroup: 2
      secrets:
        SCHEDULER_SECRET: ${taito_project}-${taito_env}-scheduler.secret
      cronJobs:
        - name: examplejob2
          schedule: "0 2 * * *"
          args:
            - /bin/sh
            - -c
            - curl -sS -H "X-Secret:$(cat $SCHEDULER_SECRET)" http://${taito_project}-${taito_env}-server:8080/posts?offset=0&limit=1

    # TODO: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#ttl-mechanism-for-finished-jobs
